{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7fc69-07c7-4f25-b0c7-1b68c476fee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37989a-2f4c-4fee-a98b-2b9f3325e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "from extract import extract_data\n",
    "from transform import handle_missing_values, encode_categoricals, normalize_features\n",
    "from load import load_data\n",
    "\n",
    "class TestETLPipeline(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        # Replace with your actual data source and paths\n",
    "        cls.source_path = '/Users/mark-danielstamakloe/Desktop/WASHU/SPRING_2024/INTRO_TO_DATA_WRANGLING/my-dagster-project/tutorial_template/notebooks'\n",
    "        cls.target_path = '/Users/mark-danielstamakloe/Desktop/WASHU/SPRING_2024/INTRO_TO_DATA_WRANGLING/my-dagster-project/tutorial_template/notebooks'\n",
    "        cls.test_data_path = '/Users/mark-danielstamakloe/Desktop/WASHU/SPRING_2024/INTRO_TO_DATA_WRANGLING/my-dagster-project/tutorial_template/notebooks'\n",
    "\n",
    "    def test_data_extraction(self):\n",
    "        # Testing the extract step\n",
    "        data = extract_data(self.source_path)\n",
    "        self.assertIsNotNone(data)\n",
    "        self.assertTrue(isinstance(data, pd.DataFrame))\n",
    "        self.assertFalse(data.empty)\n",
    "\n",
    "    def test_data_transformation(self):\n",
    "        # Load test data for transformation\n",
    "        test_data = pd.read_csv(self.test_data_path)\n",
    "        \n",
    "        # Testing handle missing values\n",
    "        data_no_missing = handle_missing_values(test_data)\n",
    "        self.assertFalse(data_no_missing.isnull().values.any())\n",
    "        \n",
    "        # Testing encode categoricals\n",
    "        data_encoded = encode_categoricals(data_no_missing)\n",
    "        # Check if a known categorical feature is encoded\n",
    "        self.assertIn('encoded_feature', data_encoded.columns)\n",
    "        \n",
    "        # Testing normalize features\n",
    "        data_normalized = normalize_features(data_encoded)\n",
    "        # Replace 'feature_to_normalize' with actual feature name\n",
    "        self.assertAlmostEqual(data_normalized['feature_to_normalize'].mean(), 0)\n",
    "\n",
    "    def test_data_loading(self):\n",
    "        # Assuming 'data_ready_to_load' is the transformed data\n",
    "        data_ready_to_load = pd.read_csv(self.test_data_path)  # As an example\n",
    "        success_flag = load_data(data_ready_to_load, self.target_path)\n",
    "        self.assertTrue(success_flag)\n",
    "        # Add additional checks if necessary, e.g., if the file exists at 'target_path'\n",
    "\n",
    "\n",
    "import unittest\n",
    "from model import train_model, make_predictions\n",
    "\n",
    "class TestModel(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Prepare your test data\n",
    "        self.features_train = # ...\n",
    "        self.target_train = # ...\n",
    "        self.features_test = # ...\n",
    "\n",
    "    def test_train_model(self):\n",
    "        model = train_model(self.features_train, self.target_train)\n",
    "        # Test if the model is fitted\n",
    "        self.assertIsNotNone(model)\n",
    "\n",
    "    def test_make_predictions(self):\n",
    "        predictions = make_predictions(model, self.features_test)\n",
    "        # Test if predictions are returned\n",
    "        self.assertTrue(len(predictions) > 0)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a7b6c-7468-479d-aadf-2454e81d665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m unittest test_etl_pipeline.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a626f-0152-4eaf-86f4-e34e91ac92be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b07e716-3ab3-45e0-8ab0-a0f3a7d5febd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3106b38-2567-4e2e-9e04-42ba39347f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
